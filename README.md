Hereâ€™s a clear, beginner-friendly `README.md` for your RAG project, designed to explain what it does, how it works, and how someone can run it from scratch.

---

## ğŸ“„ `README.md`

````markdown
# ğŸ§  RAG-Food: Simple Retrieval-Augmented Generation with ChromaDB + Ollama

This is a **minimal working RAG (Retrieval-Augmented Generation)** demo using:

- âœ… Local LLM via [Ollama](https://ollama.com/)
- âœ… Local embeddings via `mxbai-embed-large`
- âœ… [ChromaDB](https://www.trychroma.com/) as the vector database
- âœ… A simple food dataset in JSON (Indian foods, fruits, etc.)

---

## ğŸ¯ What This Does

This app allows you to ask questions like:

- â€œWhich Indian dish uses chickpeas?â€
- â€œWhat dessert is made from milk and soaked in syrup?â€
- â€œWhat is masala dosa made of?â€

It **does not rely on the LLMâ€™s built-in memory**. Instead, it:

1. **Embeds your custom text data** (about food) using `mxbai-embed-large`
2. Stores those embeddings in **ChromaDB**
3. For any question, it:
   - Embeds your question
   - Finds relevant context via similarity search
   - Passes that context + question to a local LLM (`llama3.2`)
4. Returns a natural-language answer grounded in your data.

---

## ğŸ“¦ Requirements

### âœ… Software

- Python 3.8+
- Ollama installed and running locally
- ChromaDB installed

### âœ… Ollama Models Needed

Run these in your terminal to install them:

```bash
ollama pull llama3.2
ollama pull mxbai-embed-large
````

> Make sure `ollama` is running in the background. You can test it with:
>
> ```bash
> ollama run llama3.2
> ```

---

## ğŸ› ï¸ Installation & Setup

### 1. Clone or download this repo

```bash
git clone https://github.com/yourname/rag-food
cd rag-food
```

### 2. Install Python dependencies

```bash
pip install chromadb requests
```

### 3. Run the RAG app

```bash
python rag_run.py
```

If it's the first time, it will:

* Create `foods.json` if missing
* Generate embeddings for all food items
* Load them into ChromaDB
* Run a few example questions

---

## ğŸ“ File Structure

```
rag-food/
â”œâ”€â”€ rag_run.py       # Main app script
â”œâ”€â”€ foods.json       # Food knowledge base (created if missing)
â”œâ”€â”€ README.md        # This file
```

---

## ğŸ§  How It Works (Step-by-Step)

1. **Data** is loaded from `foods.json`
2. Each entry is embedded using Ollama's `mxbai-embed-large`
3. Embeddings are stored in ChromaDB
4. When you ask a question:

   * The question is embedded
   * The top 1â€“2 most relevant chunks are retrieved
   * The context + question is passed to `llama3.2`
   * The model answers using that info only

---

## ğŸ” Try Custom Questions

You can update `rag_run.py` to include your own questions like:

```python
print(rag_query("What is tandoori chicken?"))
print(rag_query("Which foods are spicy and vegetarian?"))
```

---

## ğŸš€ Next Ideas

* Swap in larger datasets (Wikipedia articles, recipes, PDFs)
* Add a web UI with Gradio or Flask
* Cache embeddings to avoid reprocessing on every run

---

## ğŸ‘¨â€ğŸ³ Credits

Made by Callum using:

* [Ollama](https://ollama.com)
* [ChromaDB](https://www.trychroma.com)
* [mxbai-embed-large](https://ollama.com/library/mxbai-embed-large)
* Indian food inspiration ğŸ›

---

## æ‰‹åŠ¨è§¦å‘ Upsertï¼ˆGitHub Actionsï¼‰ä¸æœ¬åœ°è¿è¡Œè¯´æ˜

ä½ å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼æŠŠ `projects` è¡¨çš„æ•°æ®ä¸Šè½½åˆ° Upstash Vectorï¼ˆæˆ–é‡æ–°æ‰§è¡Œ upsertï¼‰ï¼š

1) åœ¨ GitHub ä¸Šæ‰‹åŠ¨è§¦å‘ï¼ˆæ¨èï¼Œç”¨äºè¿œç«¯ agent / CIï¼‰

- ä»“åº“å·²åŒ…å«ä¸€ä¸ªæ‰‹åŠ¨è§¦å‘çš„ Actions workflowï¼š`.github/workflows/upsert.yml`ã€‚
- åœ¨ä½¿ç”¨ä¹‹å‰ï¼Œè¯·åœ¨ä»“åº“ Settings â†’ Secrets ä¸­æ·»åŠ ä¸‹åˆ— secretsï¼š
  - `DATABASE_URL`ï¼ˆNeon/Postgres è¿æ¥å­—ç¬¦ä¸²ï¼‰
  - `UPSTASH_VECTOR_REST_URL`
  - `UPSTASH_VECTOR_REST_TOKEN`
  - å¯é€‰ï¼š`GROQ_API_KEY`ï¼ˆå¦‚æœè¿ç§»é€»è¾‘éœ€è¦è°ƒç”¨ LLMï¼‰
  - å¯é€‰ï¼š`MIGRATION_KEY`ï¼ˆå¦‚æœä½ åœ¨ serverless endpoint ä¸­å¯ç”¨äº†å¯†é’¥æ ¡éªŒï¼‰

- åœ¨ GitHub ä»“åº“é¡µé¢ï¼Œè¿›å…¥ Actions â†’ é€‰æ‹© â€œUpsert Projects to Vectorâ€ workflow â†’ ç‚¹å‡» `Run workflow` å³å¯æ‰‹åŠ¨è¿è¡Œã€‚

2) åœ¨æœ¬åœ°æ‰‹åŠ¨è¿è¡Œï¼ˆå¤‡ç”¨æˆ–è°ƒè¯•ç”¨ï¼‰

- åœ¨æœ¬åœ°ç¯å¢ƒä¸­ï¼Œè¯·ç¡®ä¿å®‰è£…ä¾èµ–å¹¶æŠŠå¿…è¦çš„ç¯å¢ƒå˜é‡åŠ å…¥ä½ çš„ shellï¼ˆæˆ–æ”¾å…¥ `.env` æ–‡ä»¶ï¼‰ã€‚ä¾‹å¦‚åœ¨ PowerShell ä¸­ï¼š

```powershell
python -m pip install -r requirements.txt
$env:DATABASE_URL = "your_database_url"
$env:UPSTASH_VECTOR_REST_URL = "https://..."
$env:UPSTASH_VECTOR_REST_TOKEN = "xxxxx"
# å¯é€‰
$env:GROQ_API_KEY = "xxxxx"
python upsert_projects_to_vector.py
```

- è„šæœ¬ `upsert_projects_to_vector.py` ä¼šè°ƒç”¨ä»“åº“ä¸­çš„è¿ç§»å·¥å…·ï¼ˆ`migrate_utils.py`ï¼‰ï¼Œå¹¶åœ¨æ§åˆ¶å°è¾“å‡ºä¸Šè½½ç»Ÿè®¡ï¼ˆä¾‹å¦‚ï¼šæ€»æ¡ç›®ã€å·² upsert æ•°é‡ã€é”™è¯¯æ•°ï¼‰ã€‚

å°æç¤ºï¼šå¦‚æœä½ æƒ³å…ˆé¢„è§ˆå°†è¦ upsert çš„å†…å®¹ï¼ˆdry-runï¼‰ï¼Œæˆ‘å¯ä»¥ä¸º `upsert_projects_to_vector.py` æ·»åŠ ä¸€ä¸ª `--dry-run` é€‰é¡¹ï¼Œæ‰“å°å‡º enriched_text å’Œ metadataï¼Œè€Œä¸å®é™…è°ƒç”¨ Upstashã€‚

---

å¦‚æœä½ éœ€è¦æˆ‘åŒæ—¶æŠŠ `--dry-run` é€‰é¡¹æ·»åŠ åˆ° upsert è„šæœ¬ï¼Œæˆ–æŠŠ workflow æ”¹æˆå¯ä»¥é€‰æ‹©åª upsert æŒ‡å®š project id çš„å½¢å¼ï¼Œå‘Šè¯‰æˆ‘ä½ æƒ³è¦çš„å‚æ•°ï¼Œæˆ‘ä¼šç»§ç»­å®ç°.
````

